[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vikram Vasan CSCI 0451 Blog",
    "section": "",
    "text": "Design and Impact of Automated Decision Systems\n\n\n\n\n\nBlog Post 2\n\n\n\n\n\nFeb 24, 2025\n\n\nVikram Vasan\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nBlog Post 1\n\n\n\n\n\nFeb 20, 2025\n\n\nVikram Vasan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html",
    "href": "posts/classifying-palmer-penguins/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "In this blog post, we explore the classification of Palmer Penguins using various machine learning models. We will discuss the dataset, preprocessing steps, model training, and evaluation. The goal of this project is to predict the species of penguins based on a subset of the available features in the Palmer Penguins dataset. There are several variables available including Culmen size, flipper length, body mass, and the island the penguin was found on, among others. We will test different combinations of quantitative and qualitative features to determine which features are most important for classification. We will also compare the performance of different machine learning models to determine which model is best suited for this task. We will test Logistic Regression, Decision Trees, Random Forest, and Support Vector Machines, using cross-validation to ensure that our results are robust. Once the best features and model is determined, we will test the model on the test set to evaluate its performance and discuss the results using plots and performance metrics."
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html#summary-statistics",
    "href": "posts/classifying-palmer-penguins/index.html#summary-statistics",
    "title": "Classifying Palmer Penguins",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nThe first task for this project is to explore the data. This will be done by creating a table of summary statistics for the data set. In order to do this we want to not only look at the quantitative data, but also the relevant qualitative data. In order to do this, for the binary data (sex and clutch completion) we can simply convert the type to an integer. For the island, it is a bit more complicated since there are 3 islands, so we will need to count the number of each island. We then simply group by the species and are able to get the averages for each variable for each species.\n\ndf_stats = train.copy()\ndf_stats[\"Female\"] = (df_stats[\"Sex\"] == \"FEMALE\").astype(int)\ndf_stats[\"Clutch Completion\"] = (df_stats[\"Clutch Completion\"] == \"Yes\").astype(int)\nsummary_table = df_stats.groupby(\"Species\").mean(numeric_only=True).drop(columns=[\"Sample Number\"])\nisland_percentages = df_stats.groupby(\"Species\")[\"Island\"].value_counts(normalize=True).unstack(fill_value=0)\nfinal_summary = summary_table.join(island_percentages)\nfinal_summary.reset_index(inplace=True)\n\ndisplay(final_summary)\n\n\n\n\n\n\n\n\nSpecies\nClutch Completion\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nFemale\nBiscoe\nDream\nTorgersen\n\n\n\n\n0\nAdelie\n0.900000\n38.970588\n18.409244\n190.084034\n3718.487395\n8.861824\n-25.796897\n0.441667\n0.275\n0.375\n0.35\n\n\n1\nChinstrap\n0.824561\n48.826316\n18.366667\n196.000000\n3743.421053\n9.331004\n-24.553401\n0.543860\n0.000\n1.000\n0.00\n\n\n2\nGentoo\n0.918367\n47.073196\n14.914433\n216.752577\n5039.948454\n8.247341\n-26.149389\n0.500000\n1.000\n0.000\n0.00\n\n\n\n\n\n\n\nLooking at the summary statistics we immediately get a clue as to which variables may or may not be useful in predicting the species. For example, Chinstrap and Gentoo penguins, only exist on one island each which, indicating that training based on the island will be very valuable. Additionally, Gentoo penguins are significantly larger with longer flippers on average while Adelie’s have much shorter Culmens than the others. The sex measurements, on the other hand, do not appear to be very useful as their distributions are more similar across the species."
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html#visualizations",
    "href": "posts/classifying-palmer-penguins/index.html#visualizations",
    "title": "Classifying Palmer Penguins",
    "section": "Visualizations",
    "text": "Visualizations\nTo get a better sense of some of the quantitative variables, we can visualize pairs of them in scatter plots. This will go further than simply using the means to see if there are any clear patterns between species in the data. We will look at the Culmen sizes, flipper lengths, body masses, and blood measurements.\n\nfig, ax = plt.subplots(1, 3, figsize = (17, 3.5))\n\np1 = sns.scatterplot(train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", hue = \"Species\", style = \"Species\", ax = ax[0])\np1 = sns.scatterplot(train, x = \"Flipper Length (mm)\", y = \"Body Mass (g)\", hue = \"Species\", style = \"Species\", ax = ax[1])\np2 = sns.scatterplot(train, x = \"Delta 15 N (o/oo)\", y = \"Delta 13 C (o/oo)\",  hue = \"Species\", style = \"Species\", ax = ax[2])\n\n\n\n\n\n\n\n\nLooking at these plots, we can see that the species are not perfectly separable on any one variable however there are clear trends. For example, the Culmen sizes form 3 pretty clear clusters, indicating that these variables, when used together, will be useful in predicting the species. The body mass and flipper length plot is also interesting as Gentoo penguins are clearly separated with Chinstrap and Adelie coming in at very similar sizes. The blood measurements are not as useful as the other variables as there is a lot of overlap between the species, but some vague groups still appear."
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html#data-preprocessing",
    "href": "posts/classifying-palmer-penguins/index.html#data-preprocessing",
    "title": "Classifying Palmer Penguins",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nNow that we have more of an idea about each variable, the next step is to train models to determine the most predictive variables. To do this, we first need to preprocess the data to binarize the categorical variables so that they can be used for the models. We will use one-hot encoding for these variables, as shown below.\n\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  x = df.drop([\"Species\"], axis = 1)\n  x = pd.get_dummies(df)\n  return x, y\n\nX_train, y_train = prepare_data(train)\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nSpecies_Adelie\nSpecies_Chinstrap\nSpecies_Gentoo\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nFalse\nFalse\nTrue\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nFalse\nFalse\nTrue\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue"
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html#variable-and-model-selection",
    "href": "posts/classifying-palmer-penguins/index.html#variable-and-model-selection",
    "title": "Classifying Palmer Penguins",
    "section": "Variable and Model Selection",
    "text": "Variable and Model Selection\nTo determine the best variable combinations, we will run some tests on different combinations of 3 variables. To do this we first generate every combination of 2 numeric and 1 categorical variable, which the following lines do so that the combinations can be used later.\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)']\n\ncombs = []\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = list(pair) + qual_cols\n    combs.append(cols)\n\nWe then loop through the combinations and use cross-validation scoring to determine which combinations perform the best. We not only want to test the variable combinations, we also want to test different models on each combination to see which one is the best. We will test the following models: Logistic Regression, Decision Tree, Random Forest, and Support Vector Machines. We will then use the best model and variables to predict the species of the test data. We test the variable combinations and models simultaneously by performing the cross-validation tests on each model for each combination.\n\nwarnings.filterwarnings('ignore')\n\ntests = []\n\nfor cols in combs:\n    LR = LogisticRegression()\n    LR.fit(X_train[cols], y_train)\n    LR.score(X_train[cols], y_train)\n    cv_scores_LR = cross_val_score(LR, X_train[cols], y_train, cv = 5)\n    DTC = DecisionTreeClassifier()\n    DTC.fit(X_train[cols], y_train)\n    DTC.score(X_train[cols], y_train)\n    cv_scores_DTC = cross_val_score(DTC, X_train[cols], y_train, cv = 5)\n    RFC = RandomForestClassifier()\n    RFC.fit(X_train[cols], y_train)\n    RFC.score(X_train[cols], y_train)\n    cv_scores_RFC = cross_val_score(RFC, X_train[cols], y_train, cv = 5)\n    SVM = SVC()\n    SVM.fit(X_train[cols], y_train)\n    SVM.score(X_train[cols], y_train)\n    cv_scores_SVM = cross_val_score(SVM, X_train[cols], y_train, cv = 5)\n    tests.append((cols, cv_scores_LR.mean(), cv_scores_DTC.mean(), cv_scores_RFC.mean(), cv_scores_SVM.mean()))\n\nTo display the outcome of these tests we use Pandas to output the average cross-validation score for each model and variable combination. Outputting just the top 5 since the number of combinations is unwieldy, we can observe some interesting things about the combinations and models.\n\ndf_results = pd.DataFrame(tests, columns=[\"Columns\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\"])\n\ndf_results[\"Columns\"] = df_results[\"Columns\"].apply(lambda x: \", \".join(x))\n\npd.set_option(\"display.max_colwidth\", None)  # no truncation of column text\n\ndf_results = df_results.sort_values(by=\"Logistic Regression\", ascending=False) # sort by cross-val score\ndf_results.reset_index(drop=True, inplace=True)\n\ndf_results.head()\n\n\n\n\n\n\n\n\nColumns\nLogistic Regression\nDecision Tree\nRandom Forest\nSVM\n\n\n\n\n0\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n0.996154\n0.976546\n0.980468\n0.820362\n\n\n1\nCulmen Length (mm), Culmen Depth (mm), Sex_FEMALE, Sex_MALE\n0.984465\n0.972624\n0.980468\n0.808673\n\n\n2\nCulmen Length (mm), Delta 13 C (o/oo), Island_Biscoe, Island_Dream, Island_Torgersen\n0.972624\n0.964932\n0.972700\n0.722700\n\n\n3\nCulmen Length (mm), Delta 15 N (o/oo), Island_Biscoe, Island_Dream, Island_Torgersen\n0.964857\n0.968778\n0.972700\n0.730543\n\n\n4\nCulmen Length (mm), Culmen Depth (mm), Clutch Completion_No, Clutch Completion_Yes\n0.957014\n0.945249\n0.949170\n0.820362\n\n\n\n\n\n\n\nFor example, the Logistic Regression tends to perform the best with SVM much inferior and the Random Forests slightly better that Decision Trees (which makes sense since Random Forests are just an extension of Decision Trees). The best variable combinations are also interesting as they are not always the same for each model. For example, the best combination for Logistic Regression is Culmen Length, Culmen Depth, and the Islands, while for Random Forests it is Culmen Length, Flipper Length, and Sex. This indicates that the models are learning different things from the data and that the best combination is not always the same. That said, as we predicted following the initial data exploration, the Culmen sizes and island are very important in predicting the species. The overall best combination was the Logistic Regression with Culmen Length, Culmen Depth, and the Islands, which had an average cross-validation score of 0.996."
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html#results",
    "href": "posts/classifying-palmer-penguins/index.html#results",
    "title": "Classifying Palmer Penguins",
    "section": "Results",
    "text": "Results\nWe then want to use these variables to train each model with the training data. We use the trained model to predict the species from the test data and compare the results to the actual species. We also test the models on the training data to see if they are overfitting. We can then output the accuracy of the model on the test and training data.\n\nX_test, y_test = prepare_data(test)\nX_test.head()\nLR = LogisticRegression()\nLR.fit(X_train[LR_cols], y_train)\nLR_train_score = LR.score(X_train[LR_cols], y_train)\nLR_test_score = LR.score(X_test[LR_cols], y_test)\n\nDTC = DecisionTreeClassifier()\nDTC.fit(X_train[DT_cols], y_train)\nDT_train_score = DTC.score(X_train[DT_cols], y_train)\nDT_test_score = DTC.score(X_test[DT_cols], y_test)\n\nRFC = RandomForestClassifier()\nRFC.fit(X_train[RF_cols], y_train)\nRF_train_score = RFC.score(X_train[RF_cols], y_train)\nRF_test_score = RFC.score(X_test[RF_cols], y_test)\n\nSVM = SVC()\nSVM.fit(X_train[SVM_cols], y_train)\nSVM_train_score = SVM.score(X_train[SVM_cols], y_train)\nSVM_test_score = SVM.score(X_test[SVM_cols], y_test)\n\nscores = [[LR_train_score, LR_test_score, LR_cols], [DT_train_score, DT_test_score, DT_cols], [RF_train_score, RF_test_score, RF_cols], [SVM_train_score, SVM_test_score, SVM_cols]]\n\ndf_scores = pd.DataFrame(scores, columns=[\"Training Accuracy\", \"Testing Accuracy\", \"Variables\"])\ndf_scores[\"Model\"] = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\"]\ndf_scores[\"Training Accuracy\"] = df_scores[\"Training Accuracy\"].round(3)\ndf_scores[\"Testing Accuracy\"] = df_scores[\"Testing Accuracy\"].round(3)\ndf_scores[\"Variables\"] = df_scores[\"Variables\"].apply(lambda x: \", \".join(x))\ndf_scores = df_scores[[\"Model\", \"Training Accuracy\", \"Testing Accuracy\", \"Variables\"]]\ndisplay(df_scores)\n\n\n\n\n\n\n\n\nModel\nTraining Accuracy\nTesting Accuracy\nVariables\n\n\n\n\n0\nLogistic Regression\n0.996\n1.000\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n\n\n1\nDecision Tree\n1.000\n0.985\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n\n\n2\nRandom Forest\n1.000\n0.971\nCulmen Length (mm), Flipper Length (mm), Sex_FEMALE, Sex_MALE\n\n\n3\nSVM\n0.891\n0.941\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n\n\n\n\n\n\n\nHere, we see that the Logistic Regression model with Culmen Length, Culmen Depth, and Island achieves an impressive 100% testing accuracy which is exactly what we were looking for. The training accuracy is also very high at 99.6% which indicates that the model is not overfitting. The other models also perform well, but not as well as the Logistic Regression model. The Decision Tree model with same variables is the next best with a testing accuracy of 98.5% and a training accuracy of 100%. The Random Forest model with Culmen Length, Flipper Length, and Sex also did well with a testing accuracy of 97.1% and a training accuracy of 100%. The SVM model did the worse with a testing accuracy of 94.1% and a training accuracy of 89.1%.\nIt is interesting that the best variables for 3 of the 4 models is Culmen Length, Culmen Depth, and Island. This indicates that these variables are the most important in predicting the species. The Random Forest model is the only one that has a different best variable combination, which is Culmen Length, Flipper Length, and Sex, which is interesting as it indicates that the model is learning something different from the data. The Logistic Regression model is the best overall, which is not surprising as it was the best in the cross-validation tests."
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html#visualizations-1",
    "href": "posts/classifying-palmer-penguins/index.html#visualizations-1",
    "title": "Classifying Palmer Penguins",
    "section": "Visualizations",
    "text": "Visualizations\nNow that we know that the Logistic Regression model with Culmen Length, Culmen Depth, and Island as variables is the best model, we can visualize the results. We plot the Culmen length and depth split by island and colored by species for both the training and test data. We also show the decision regions as determined by the model.\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i].replace(\"_\", \" \"))\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nplot_regions(LR, X_train[LR_cols], y_train)\nplot_regions(LR, X_test[LR_cols], y_test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis visualization shows that the model is able to separate the species very well. The decision boundaries are very clear and the model is able to predict the species in the testing data with 100% accuracy. This is a very good result and indicates that the model is quite good at predicting the species of penguins using only the chosen variables. It is also clear that, as we expected, the Island is very helpful as Gentoo penguins are the only species that exist across all 3 islands, greatly simplifying the prediction complexity.\n\ny_test_pred = LR.predict(X_test[LR_cols])\nC = confusion_matrix(y_test, y_test_pred)\n\nclass_labels = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n\nplt.figure(figsize=(6,4))\nsns.heatmap(C, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we want to take a look at the confusion matrix. Since we had 100% test accuracy, we expect the confusion matrix to be a diagonal matrix with numbers on the diagonal and 0s elsewhere. This is exactly what we see, which is a good sign that the model is working well. All of the species are predicted perfectly, which is exactly what we were looking for."
  },
  {
    "objectID": "posts/design-and-impact of-automated-decision-systems/index.html",
    "href": "posts/design-and-impact of-automated-decision-systems/index.html",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "",
    "text": "In this blog post, we explore the classification of Palmer Penguins using various machine learning models. We will discuss the dataset, preprocessing steps, model training, and evaluation. The goal of this project is to predict the species of penguins based on a subset of the available features in the Palmer Penguins dataset. There are several variables available including Culmen size, flipper length, body mass, and the island the penguin was found on, among others. We will test different combinations of quantitative and qualitative features to determine which features are most important for classification. We will also compare the performance of different machine learning models to determine which model is best suited for this task. We will test Logistic Regression, Decision Trees, Random Forest, and Support Vector Machines, using cross-validation to ensure that our results are robust. Once the best features and model is determined, we will test the model on the test set to evaluate its performance and discuss the results using plots and performance metrics."
  },
  {
    "objectID": "posts/design-and-impact of-automated-decision-systems/index.html#summary-statistics",
    "href": "posts/design-and-impact of-automated-decision-systems/index.html#summary-statistics",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Summary Statistics",
    "text": "Summary Statistics\n\ndf_stats = df_train.copy()\ndf_stats[\"cb_person_default_on_file\"] = (df_stats[\"cb_person_default_on_file\"] == \"Y\").astype(int)\ndf_stats[\"loan_status\"] = df_stats[\"loan_status\"].map({1: \"default\", 0: \"repaid\"})\nsummary_table = df_stats.groupby(\"loan_status\").mean(numeric_only=True)\nhome_ownership_percentages = df_stats.groupby(\"loan_status\")[\"person_home_ownership\"].value_counts(normalize=True).unstack(fill_value=0)\nloan_intent_percentages = df_stats.groupby(\"loan_status\")[\"loan_intent\"].value_counts(normalize=True).unstack(fill_value=0)\nloan_grade_percentages = df_stats.groupby(\"loan_status\")[\"loan_grade\"].value_counts(normalize=True).unstack(fill_value=0)\nfinal_summary = summary_table.join(home_ownership_percentages).join(loan_intent_percentages).join(loan_grade_percentages)\nfinal_summary.reset_index(inplace=True)\nfinal_summary.columns = final_summary.columns.str.replace('_', ' ').str.title()\nfinal_summary = final_summary.round(3)\n\ndisplay(final_summary)\n\n\n\n\n\n\n\n\nLoan Status\nPerson Age\nPerson Income\nPerson Emp Length\nLoan Amnt\nLoan Int Rate\nLoan Percent Income\nCb Person Default On File\nCb Person Cred Hist Length\nMortgage\n...\nMedical\nPersonal\nVenture\nA\nB\nC\nD\nE\nF\nG\n\n\n\n\n0\ndefault\n27.439\n48883.177\n4.159\n10769.053\n13.061\n0.246\n0.303\n5.652\n0.236\n...\n0.224\n0.151\n0.121\n0.154\n0.236\n0.187\n0.302\n0.088\n0.024\n0.008\n\n\n1\nrepaid\n27.817\n70727.745\n4.954\n9235.881\n10.437\n0.149\n0.140\n5.834\n0.460\n...\n0.175\n0.174\n0.193\n0.381\n0.342\n0.202\n0.058\n0.014\n0.003\n0.000\n\n\n\n\n2 rows × 26 columns"
  },
  {
    "objectID": "posts/design-and-impact of-automated-decision-systems/index.html#visualizations",
    "href": "posts/design-and-impact of-automated-decision-systems/index.html#visualizations",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Visualizations",
    "text": "Visualizations\n\nfig, ax = plt.subplots(1, 3, figsize = (17, 3.5))\n\np1 = sns.scatterplot(train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", hue = \"Species\", style = \"Species\", ax = ax[0])\np1 = sns.scatterplot(train, x = \"Flipper Length (mm)\", y = \"Body Mass (g)\", hue = \"Species\", style = \"Species\", ax = ax[1])\np2 = sns.scatterplot(train, x = \"Delta 15 N (o/oo)\", y = \"Delta 13 C (o/oo)\",  hue = \"Species\", style = \"Species\", ax = ax[2])"
  },
  {
    "objectID": "posts/design-and-impact of-automated-decision-systems/index.html#data-preprocessing",
    "href": "posts/design-and-impact of-automated-decision-systems/index.html#data-preprocessing",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\n\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  x = df.drop([\"Species\"], axis = 1)\n  x = pd.get_dummies(df)\n  return x, y\n\nX_train, y_train = prepare_data(train)\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nSpecies_Adelie\nSpecies_Chinstrap\nSpecies_Gentoo\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nFalse\nFalse\nTrue\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nFalse\nFalse\nTrue\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue"
  },
  {
    "objectID": "posts/design-and-impact of-automated-decision-systems/index.html#variable-and-model-selection",
    "href": "posts/design-and-impact of-automated-decision-systems/index.html#variable-and-model-selection",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Variable and Model Selection",
    "text": "Variable and Model Selection\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)']\n\ncombs = []\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = list(pair) + qual_cols\n    combs.append(cols)\n\n–\n\nwarnings.filterwarnings('ignore')\n\ntests = []\n\nfor cols in combs:\n    LR = LogisticRegression()\n    LR.fit(X_train[cols], y_train)\n    LR.score(X_train[cols], y_train)\n    cv_scores_LR = cross_val_score(LR, X_train[cols], y_train, cv = 5)\n    DTC = DecisionTreeClassifier()\n    DTC.fit(X_train[cols], y_train)\n    DTC.score(X_train[cols], y_train)\n    cv_scores_DTC = cross_val_score(DTC, X_train[cols], y_train, cv = 5)\n    RFC = RandomForestClassifier()\n    RFC.fit(X_train[cols], y_train)\n    RFC.score(X_train[cols], y_train)\n    cv_scores_RFC = cross_val_score(RFC, X_train[cols], y_train, cv = 5)\n    SVM = SVC()\n    SVM.fit(X_train[cols], y_train)\n    SVM.score(X_train[cols], y_train)\n    cv_scores_SVM = cross_val_score(SVM, X_train[cols], y_train, cv = 5)\n    tests.append((cols, cv_scores_LR.mean(), cv_scores_DTC.mean(), cv_scores_RFC.mean(), cv_scores_SVM.mean()))\n\n–\n\ndf_results = pd.DataFrame(tests, columns=[\"Columns\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\"])\n\ndf_results[\"Columns\"] = df_results[\"Columns\"].apply(lambda x: \", \".join(x))\n\npd.set_option(\"display.max_colwidth\", None)  # no truncation of column text\n\ndf_results = df_results.sort_values(by=\"Logistic Regression\", ascending=False) # sort by cross-val score\ndf_results.reset_index(drop=True, inplace=True)\n\ndf_results.head()\n\n\n\n\n\n\n\n\nColumns\nLogistic Regression\nDecision Tree\nRandom Forest\nSVM\n\n\n\n\n0\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n0.996154\n0.976546\n0.980468\n0.820362\n\n\n1\nCulmen Length (mm), Culmen Depth (mm), Sex_FEMALE, Sex_MALE\n0.984465\n0.972624\n0.980468\n0.808673\n\n\n2\nCulmen Length (mm), Delta 13 C (o/oo), Island_Biscoe, Island_Dream, Island_Torgersen\n0.972624\n0.964932\n0.972700\n0.722700\n\n\n3\nCulmen Length (mm), Delta 15 N (o/oo), Island_Biscoe, Island_Dream, Island_Torgersen\n0.964857\n0.968778\n0.972700\n0.730543\n\n\n4\nCulmen Length (mm), Culmen Depth (mm), Clutch Completion_No, Clutch Completion_Yes\n0.957014\n0.945249\n0.949170\n0.820362\n\n\n\n\n\n\n\n–"
  },
  {
    "objectID": "posts/design-and-impact of-automated-decision-systems/index.html#results",
    "href": "posts/design-and-impact of-automated-decision-systems/index.html#results",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Results",
    "text": "Results\n\nX_test, y_test = prepare_data(test)\nX_test.head()\nLR = LogisticRegression()\nLR.fit(X_train[LR_cols], y_train)\nLR_train_score = LR.score(X_train[LR_cols], y_train)\nLR_test_score = LR.score(X_test[LR_cols], y_test)\n\nDTC = DecisionTreeClassifier()\nDTC.fit(X_train[DT_cols], y_train)\nDT_train_score = DTC.score(X_train[DT_cols], y_train)\nDT_test_score = DTC.score(X_test[DT_cols], y_test)\n\nRFC = RandomForestClassifier()\nRFC.fit(X_train[RF_cols], y_train)\nRF_train_score = RFC.score(X_train[RF_cols], y_train)\nRF_test_score = RFC.score(X_test[RF_cols], y_test)\n\nSVM = SVC()\nSVM.fit(X_train[SVM_cols], y_train)\nSVM_train_score = SVM.score(X_train[SVM_cols], y_train)\nSVM_test_score = SVM.score(X_test[SVM_cols], y_test)\n\nscores = [[LR_train_score, LR_test_score, LR_cols], [DT_train_score, DT_test_score, DT_cols], [RF_train_score, RF_test_score, RF_cols], [SVM_train_score, SVM_test_score, SVM_cols]]\n\ndf_scores = pd.DataFrame(scores, columns=[\"Training Accuracy\", \"Testing Accuracy\", \"Variables\"])\ndf_scores[\"Model\"] = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\"]\ndf_scores[\"Training Accuracy\"] = df_scores[\"Training Accuracy\"].round(3)\ndf_scores[\"Testing Accuracy\"] = df_scores[\"Testing Accuracy\"].round(3)\ndf_scores[\"Variables\"] = df_scores[\"Variables\"].apply(lambda x: \", \".join(x))\ndf_scores = df_scores[[\"Model\", \"Training Accuracy\", \"Testing Accuracy\", \"Variables\"]]\ndisplay(df_scores)\n\n\n\n\n\n\n\n\nModel\nTraining Accuracy\nTesting Accuracy\nVariables\n\n\n\n\n0\nLogistic Regression\n0.996\n1.000\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n\n\n1\nDecision Tree\n1.000\n0.985\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n\n\n2\nRandom Forest\n1.000\n0.971\nCulmen Length (mm), Flipper Length (mm), Sex_FEMALE, Sex_MALE\n\n\n3\nSVM\n0.891\n0.941\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen"
  },
  {
    "objectID": "posts/design-and-impact of-automated-decision-systems/index.html#visualizations-1",
    "href": "posts/design-and-impact of-automated-decision-systems/index.html#visualizations-1",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Visualizations",
    "text": "Visualizations\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i].replace(\"_\", \" \"))\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nplot_regions(LR, X_train[LR_cols], y_train)\nplot_regions(LR, X_test[LR_cols], y_test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–\n\ny_test_pred = LR.predict(X_test[LR_cols])\nC = confusion_matrix(y_test, y_test_pred)\n\nclass_labels = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n\nplt.figure(figsize=(6,4))\nsns.heatmap(C, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()"
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html#summary-statistics",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html#summary-statistics",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nThe first task is to explore the data, and understand the distribution of the features as they relate to the target variable. We will start by grouping the data by the target variable and calculating the mean of each feature. This will give us an idea of how the features differ between the two groups.\n\ndf_stats = df_train.copy()\ndf_stats[\"cb_person_default_on_file\"] = (df_stats[\"cb_person_default_on_file\"] == \"Y\").astype(int)\ndf_stats[\"loan_status\"] = df_stats[\"loan_status\"].map({1: \"Default\", 0: \"Repaid\"})\nsummary_table = df_stats.groupby(\"loan_status\").mean(numeric_only=True)\nhome_ownership_percentages = df_stats.groupby(\"loan_status\")[\"person_home_ownership\"].value_counts(normalize=True).unstack(fill_value=0)\nloan_intent_percentages = df_stats.groupby(\"loan_status\")[\"loan_intent\"].value_counts(normalize=True).unstack(fill_value=0)\nfinal_summary = summary_table.join(home_ownership_percentages).join(loan_intent_percentages)\nfinal_summary.reset_index(inplace=True)\nfinal_summary.columns = final_summary.columns.str.replace('_', ' ').str.title()\nfinal_summary = final_summary.round(3)\n\ndisplay(final_summary)\n\n\n\n\n\n\n\n\nLoan Status\nPerson Age\nPerson Income\nPerson Emp Length\nLoan Amnt\nLoan Int Rate\nLoan Percent Income\nCb Person Default On File\nCb Person Cred Hist Length\nMortgage\nOther\nOwn\nRent\nDebtconsolidation\nEducation\nHomeimprovement\nMedical\nPersonal\nVenture\n\n\n\n\n0\nDefault\n27.439\n48883.177\n4.159\n10769.053\n0.131\n0.246\n0.303\n5.652\n0.236\n0.005\n0.030\n0.729\n0.212\n0.157\n0.135\n0.224\n0.151\n0.121\n\n\n1\nRepaid\n27.817\n70727.745\n4.954\n9235.881\n0.104\n0.149\n0.140\n5.834\n0.460\n0.003\n0.094\n0.443\n0.146\n0.208\n0.105\n0.175\n0.174\n0.193\n\n\n\n\n\n\n\nLooking solely at the means, we see some interesting differences between defaulted and repaid loans. For example, as one would expect, defaulted loans have a higher average loan percent of income and interest rate. This makes sense because if a loan is a larger percent of ones income, it is harder to pay off. Similarly, a higher interest rate would make it more difficult to pay off the loan. It is also interesting to see that 73% of defaulted loans are taken out by individuals who rent their homes, compared to only 44% for repaid loans. This could be due to the fact that renters have less disposable income than homeowners. Finally, the loan amount averages is curious because the average loan amount doesn’t differ that much between groups. One would expect that defaulted loans would have a higher average loan amount, but this is only slightly the case."
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html#visualizations",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html#visualizations",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Visualizations",
    "text": "Visualizations\nTo get a better idea of the characteristics of the data, we will continue by plotting some of the more interesting variables. We will scatter two continuous variables against each other, and color the points by the outcome of the loan. This will give us more of an idea of the relationships than the mean can give us. We will also calculate a line of best fit for each pairing to get a sense for whether the relationship is particularly predictive.\n\ndf_vis = df_train.copy()\ndf_vis[\"loan_status\"] = df_vis[\"loan_status\"].map({1: \"Default\", 0: \"Repaid\"})\ndf_vis.columns = df_vis.columns.str.replace('_', ' ').str.title()\n\nfig, ax = plt.subplots(1, 3, figsize=(17, 3.5))\n\n# define colors for each loan_status\npalette = [\"blue\", \"#C76E00\"]\n\np1 = sns.scatterplot(df_vis, x=\"Person Emp Length\", y=\"Person Income\", hue=\"Loan Status\", ax=ax[0])\nax[0].set_xlim(0, 42)\nax[0].set_ylim(0, 1000000)  # To remove outliers\nfor i, status in enumerate(df_vis[\"Loan Status\"].unique()):\n    subset = df_vis[df_vis[\"Loan Status\"] == status]\n    sns.regplot(data=subset, x=\"Person Emp Length\", y=\"Person Income\", scatter=False, ci=None, ax=ax[0], color=palette[i])\n\np2 = sns.scatterplot(df_vis, x=\"Loan Amnt\", y=\"Loan Percent Income\", hue=\"Loan Status\", ax=ax[1])\nfor i, status in enumerate(df_vis[\"Loan Status\"].unique()):\n    subset = df_vis[df_vis[\"Loan Status\"] == status]\n    sns.regplot(data=subset, x=\"Loan Amnt\", y=\"Loan Percent Income\", scatter=False, ci=None, ax=ax[1], color=palette[i])\n\np3 = sns.scatterplot(df_vis, x=\"Cb Person Cred Hist Length\", y=\"Loan Int Rate\", hue=\"Loan Status\", ax=ax[2])\nfor i, status in enumerate(df_vis[\"Loan Status\"].unique()):\n    subset = df_vis[df_vis[\"Loan Status\"] == status]\n    sns.regplot(data=subset, x=\"Cb Person Cred Hist Length\", y=\"Loan Int Rate\", scatter=False, ci=None, ax=ax[2], color=palette[i])\n\nplt.show()\n\n\n\n\n\n\n\n\nThe first plot of income vs employment length is interesting because it is contrary to what we observed in the summary statistics. Both income and employment length appear to have very little between them when it comes to loan status. The lines of best fit for each group almost overlap indicating that the difference between groups is marginal. This is surprising because the summary statistics showed that the average income of borrowers who repay their loans is over $20,000 higher than those who default. This is a case where means can be deceiving because a lot of that difference can be accounted for by a few outliers with very high incomes. The lines of best fit recognize this and show that the relationship is not as strong as the mean would suggest.\nThe second plot of loan amount vs loan percent of income is more in line with what we would expect. The line of best fit for defaulted loans is steeper and higher than that of repaid loans, indicating that the loan amount is more predictive of loan status than income. This makes sense because the relative size of a loan to one’s income is a better indicator of whether they can pay it back than income alone. Finally, the third plot shows the interest rate against the credit history length. The lines of best fit are very separated indicating that interest rate has a significant impact on ability to repay as we anticipated."
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html#data-preprocessing",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html#data-preprocessing",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nThe next step is to train a model on the data. The first thing we need to do, in order to accomplish this, is to preprocess the data. This involves removing the target variable from the feature set and using one-hot encoding to binarize the categorical variables.\n\nle = LabelEncoder()\nle.fit(df_train[\"loan_status\"])\n\ndef prepare_data(df):\n  df = df.dropna()\n  y = le.transform(df[\"loan_status\"])\n  x = df.drop([\"loan_status\", \"loan_grade\"], axis = 1)\n  x = pd.get_dummies(x)\n  return x, y\n\nX_train, y_train = prepare_data(df_train)\nX_train = X_train.reset_index(drop=True)\n\nX_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_percent_income\ncb_person_cred_hist_length\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\nperson_home_ownership_OWN\nperson_home_ownership_RENT\nloan_intent_DEBTCONSOLIDATION\nloan_intent_EDUCATION\nloan_intent_HOMEIMPROVEMENT\nloan_intent_MEDICAL\nloan_intent_PERSONAL\nloan_intent_VENTURE\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\n\n\n\n\n0\n27\n98000\n3.0\n11750\n0.1347\n0.12\n6\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n1\n22\n36996\n5.0\n10000\n0.0751\n0.27\n4\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n2\n24\n26000\n2.0\n1325\n0.1287\n0.05\n4\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\n\n\n3\n29\n53004\n2.0\n15000\n0.0963\n0.28\n10\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n4\n21\n21700\n2.0\n5500\n0.1491\n0.25\n2\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse"
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html#variable-and-model-selection",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html#variable-and-model-selection",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Variable and Model Selection",
    "text": "Variable and Model Selection\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)']\n\ncombs = []\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = list(pair) + qual_cols\n    combs.append(cols)\n\n–\n\nwarnings.filterwarnings('ignore')\n\ntests = []\n\nfor cols in combs:\n    LR = LogisticRegression()\n    LR.fit(X_train[cols], y_train)\n    LR.score(X_train[cols], y_train)\n    cv_scores_LR = cross_val_score(LR, X_train[cols], y_train, cv = 5)\n    DTC = DecisionTreeClassifier()\n    DTC.fit(X_train[cols], y_train)\n    DTC.score(X_train[cols], y_train)\n    cv_scores_DTC = cross_val_score(DTC, X_train[cols], y_train, cv = 5)\n    RFC = RandomForestClassifier()\n    RFC.fit(X_train[cols], y_train)\n    RFC.score(X_train[cols], y_train)\n    cv_scores_RFC = cross_val_score(RFC, X_train[cols], y_train, cv = 5)\n    SVM = SVC()\n    SVM.fit(X_train[cols], y_train)\n    SVM.score(X_train[cols], y_train)\n    cv_scores_SVM = cross_val_score(SVM, X_train[cols], y_train, cv = 5)\n    tests.append((cols, cv_scores_LR.mean(), cv_scores_DTC.mean(), cv_scores_RFC.mean(), cv_scores_SVM.mean()))\n\n–\n\ndf_results = pd.DataFrame(tests, columns=[\"Columns\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\"])\n\ndf_results[\"Columns\"] = df_results[\"Columns\"].apply(lambda x: \", \".join(x))\n\npd.set_option(\"display.max_colwidth\", None)  # no truncation of column text\n\ndf_results = df_results.sort_values(by=\"Logistic Regression\", ascending=False) # sort by cross-val score\ndf_results.reset_index(drop=True, inplace=True)\n\ndf_results.head()\n\n\n\n\n\n\n\n\nColumns\nLogistic Regression\nDecision Tree\nRandom Forest\nSVM\n\n\n\n\n0\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n0.996154\n0.976546\n0.980468\n0.820362\n\n\n1\nCulmen Length (mm), Culmen Depth (mm), Sex_FEMALE, Sex_MALE\n0.984465\n0.972624\n0.980468\n0.808673\n\n\n2\nCulmen Length (mm), Delta 13 C (o/oo), Island_Biscoe, Island_Dream, Island_Torgersen\n0.972624\n0.964932\n0.972700\n0.722700\n\n\n3\nCulmen Length (mm), Delta 15 N (o/oo), Island_Biscoe, Island_Dream, Island_Torgersen\n0.964857\n0.968778\n0.972700\n0.730543\n\n\n4\nCulmen Length (mm), Culmen Depth (mm), Clutch Completion_No, Clutch Completion_Yes\n0.957014\n0.945249\n0.949170\n0.820362\n\n\n\n\n\n\n\n–"
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html#results",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html#results",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Results",
    "text": "Results\n\nX_test, y_test = prepare_data(test)\nX_test.head()\nLR = LogisticRegression()\nLR.fit(X_train[LR_cols], y_train)\nLR_train_score = LR.score(X_train[LR_cols], y_train)\nLR_test_score = LR.score(X_test[LR_cols], y_test)\n\nDTC = DecisionTreeClassifier()\nDTC.fit(X_train[DT_cols], y_train)\nDT_train_score = DTC.score(X_train[DT_cols], y_train)\nDT_test_score = DTC.score(X_test[DT_cols], y_test)\n\nRFC = RandomForestClassifier()\nRFC.fit(X_train[RF_cols], y_train)\nRF_train_score = RFC.score(X_train[RF_cols], y_train)\nRF_test_score = RFC.score(X_test[RF_cols], y_test)\n\nSVM = SVC()\nSVM.fit(X_train[SVM_cols], y_train)\nSVM_train_score = SVM.score(X_train[SVM_cols], y_train)\nSVM_test_score = SVM.score(X_test[SVM_cols], y_test)\n\nscores = [[LR_train_score, LR_test_score, LR_cols], [DT_train_score, DT_test_score, DT_cols], [RF_train_score, RF_test_score, RF_cols], [SVM_train_score, SVM_test_score, SVM_cols]]\n\ndf_scores = pd.DataFrame(scores, columns=[\"Training Accuracy\", \"Testing Accuracy\", \"Variables\"])\ndf_scores[\"Model\"] = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"SVM\"]\ndf_scores[\"Training Accuracy\"] = df_scores[\"Training Accuracy\"].round(3)\ndf_scores[\"Testing Accuracy\"] = df_scores[\"Testing Accuracy\"].round(3)\ndf_scores[\"Variables\"] = df_scores[\"Variables\"].apply(lambda x: \", \".join(x))\ndf_scores = df_scores[[\"Model\", \"Training Accuracy\", \"Testing Accuracy\", \"Variables\"]]\ndisplay(df_scores)\n\n\n\n\n\n\n\n\nModel\nTraining Accuracy\nTesting Accuracy\nVariables\n\n\n\n\n0\nLogistic Regression\n0.996\n1.000\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n\n\n1\nDecision Tree\n1.000\n0.985\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen\n\n\n2\nRandom Forest\n1.000\n0.971\nCulmen Length (mm), Flipper Length (mm), Sex_FEMALE, Sex_MALE\n\n\n3\nSVM\n0.891\n0.941\nCulmen Length (mm), Culmen Depth (mm), Island_Biscoe, Island_Dream, Island_Torgersen"
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html#visualizations-1",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html#visualizations-1",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Visualizations",
    "text": "Visualizations\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i].replace(\"_\", \" \"))\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nplot_regions(LR, X_train[LR_cols], y_train)\nplot_regions(LR, X_test[LR_cols], y_test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–\n\ny_test_pred = LR.predict(X_test[LR_cols])\nC = confusion_matrix(y_test, y_test_pred)\n\nclass_labels = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n\nplt.figure(figsize=(6,4))\nsns.heatmap(C, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()"
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "",
    "text": "In this blog post, we will be exploring bank loan data, specifically inquiring about the ability to predict loan success based on borrower characteristics. The data includes information about the borrower, loan amount, loan status, and other relevant information. Loan status is the target variable, where 1 indicates a default and 0 means the loan was repaid. We will test different combinations of features with a Logistic Regression model to discover the most predictive indicators of loan success. We will then discuss the results including an investigation of how different groups would be affected if the model were to be implemented."
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html#feature-selection",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html#feature-selection",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Feature Selection",
    "text": "Feature Selection\nWith the data processed, we now need to determine which features to include in the model. To do this we will perform an exhaustive search of every combination of 3 features and use cross-validation scores to compare them. The following code will perform these tests by training a logistic regression model on each combination of features and calculating the cross-validation score. The best combination of features will be the one with the highest cross-validation score.\n\nwarnings.filterwarnings('ignore')\nattributes = X_train.columns\ncombs = list(combinations(attributes, 3))\n\ntests = []\n\nfor cols in combs:\n    LR = LogisticRegression()\n    LR.fit(X_train[list(cols)], y_train)\n    LR.score(X_train[list(cols)], y_train)\n    cv_scores = cross_val_score(LR, X_train[list(cols)], y_train, cv = 5)\n    tests.append((list(cols), cv_scores.mean()))\n\nTo find the best combination we will sort by cross-validation score and display the top 5 combinations.\n\ndf_results = pd.DataFrame(tests, columns=[\"Columns\", \"Cross-Validation Score\"])\n\ndf_results[\"Columns\"] = df_results[\"Columns\"].apply(lambda x: \", \".join(x))\n\npd.set_option(\"display.max_colwidth\", None)  # no truncation of column text\n\ndf_results = df_results.sort_values(by=\"Cross-Validation Score\", ascending=False) # sort by cross-val score\ndf_results.reset_index(drop=True, inplace=True)\n\ndf_results.head()\n\n\n\n\n\n\n\n\nColumns\nCross-Validation Score\n\n\n\n\n0\nloan_percent_income, person_home_ownership_RENT, loan_intent_HOMEIMPROVEMENT\n0.849521\n\n\n1\nloan_percent_income, person_home_ownership_RENT, loan_intent_DEBTCONSOLIDATION\n0.849260\n\n\n2\nloan_percent_income, person_home_ownership_OTHER, person_home_ownership_RENT\n0.849216\n\n\n3\nloan_percent_income, person_home_ownership_MORTGAGE, person_home_ownership_OWN\n0.848736\n\n\n4\nloan_percent_income, person_home_ownership_RENT, loan_intent_MEDICAL\n0.848430\n\n\n\n\n\n\n\nAs the above table shows, the combination of loan percent of income, person home ownership: rent, and loan intent: home improvement performs the best with a cross-validation score of 0.8495. This makes sense with our initial exploration as we recognized the big difference between groups in loan percent of income and home ownership status.\nWith the best combination of features determined, we can now train the model on the entire dataset and evaluate its performance. By training a logistic regression model on the training columns we are able to obtain a weight vector which can be used to score new data.\n\ncols = df_results[\"Columns\"].iloc[0].split(\", \")\nLR = LogisticRegression()\nLR.fit(X_train[cols], y_train)\nLR_train_score = LR.score(X_train[cols], y_train)\nprint(f\"Training Score: {LR_train_score}\")\nw = LR.coef_[0]\nprint(f\"Weight Vector (w): {w}\")\n\nTraining Score: 0.8493473610686689\nWeight Vector (w): [8.14642112 1.19649321 0.49192603]\n\n\nAbove we see the training score which matches the cross-validation score, as expected, as well as the weight vector which we will use in the next section to find a threshold."
  },
  {
    "objectID": "posts/design-and-impact-of-automated-decision-systems/index.html#evaluate-from-the-borrowers-perspective",
    "href": "posts/design-and-impact-of-automated-decision-systems/index.html#evaluate-from-the-borrowers-perspective",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Evaluate from the Borrower’s Perspective",
    "text": "Evaluate from the Borrower’s Perspective\nWe next want to consider how the implementation of this model would affect borrowers. We will first look at different age groups by binning the ages and calculating the acceptance rate for each group. We will then calculate the acceptance rate for different income levels and loan purposes.\n\nbins = [X_test[\"person_age\"].min(), 25, 35, 45, 55, 65, X_test[\"person_age\"].max()]\nlabels = [\"&lt;25\", \"25-35\", \"35-45\", \"45-55\", \"55-65\", \"65+\"]\n\nX_test[\"age_group\"] = pd.cut(X_test[\"person_age\"], bins=bins, labels=labels, include_lowest=True)\n\nacceptance_rates_age = X_test.groupby(\"age_group\").apply(lambda group: np.mean(preds[group.index] == 0))\n\nplt.figure(figsize=(8, 5))\nsns.barplot(x=acceptance_rates_age.index, y=acceptance_rates_age.values, palette=\"Blues_r\")\n\nplt.xlabel(\"Age Group\")\nplt.ylabel(\"Acceptance Rate\")\nplt.title(\"Acceptance Rates by Age\")\nplt.ylim(0.75, 1)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n\nplt.show()\n\n\n\n\n\n\n\n\nAs the plot above shows, the acceptance rate is a bell curve with people between 35 and 55 having the highest acceptance rate. This makes logical sense because younger people are less settled and thus more risky to lend to while death becomes a worry when lending to older people. People in the middle are more likely to have stable jobs and thus be able to pay back the loan.\n\nX_test[\"predict_default\"] = preds\nX_test[\"loan_status\"] = y_test\n\nmedical = X_test.groupby(\"loan_intent_MEDICAL\")[[\"predict_default\", \"loan_status\"]].mean().reset_index()\nventure = X_test.groupby(\"loan_intent_VENTURE\")[[\"predict_default\", \"loan_status\"]].mean().reset_index()\neducation = X_test.groupby(\"loan_intent_EDUCATION\")[[\"predict_default\", \"loan_status\"]].mean().reset_index()\n\nmedical = medical.rename(columns={\"loan_intent_MEDICAL\": \"Medical\", \"predict_default\": \"Predicted Default Rate\", \"loan_status\": \"Actual Default Rate\"})\nventure = venture.rename(columns={\"loan_intent_VENTURE\": \"Business Venture\", \"predict_default\": \"Predicted Default Rate\", \"loan_status\": \"Actual Default Rate\"})\neducation = education.rename(columns={\"loan_intent_EDUCATION\": \"Education\", \"predict_default\": \"Predicted Default Rate\", \"loan_status\": \"Actual Default Rate\"})\n\ndisplay(medical, venture, education)\n\n\n\n\n\n\n\n\nMedical\nPredicted Default Rate\nActual Default Rate\n\n\n\n\n0\nFalse\n0.086518\n0.208673\n\n\n1\nTrue\n0.103448\n0.284250\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBusiness Venture\nPredicted Default Rate\nActual Default Rate\n\n\n\n\n0\nFalse\n0.091252\n0.238305\n\n\n1\nTrue\n0.081950\n0.146266\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEducation\nPredicted Default Rate\nActual Default Rate\n\n\n\n\n0\nFalse\n0.093304\n0.237102\n\n\n1\nTrue\n0.075680\n0.167517\n\n\n\n\n\n\n\nLooking at the default predictions by loan intent and comparing them with the actual outcome is also interesting. The predicted default rate for medical intended loans is higher than other loans, and the actual default rate reflects this trend as well. This makes sense because medical loans are often taken out of necessity rather than choice so the individuals involved don’t have the luxury to consider whether or not they will be able to pay them back. Loans for business ventures and education, on the other hand, have a lower predicted default rate and this is reflected in the actual default rate as well. This is likely because these loans are taken out with the intention of making money in the future, so if that comes to pass these individuals will be able to repay their loans more easily.\n\nquartiles, bin_edges = pd.qcut(X_test[\"person_income\"], q=6, retbins=True, labels=False)\n\nlabels = [f\"${int(bin_edges[i])}-{int(bin_edges[i+1])}\" for i in range(len(bin_edges)-1)]\nlabels[0] = f\"&lt;${int(bin_edges[1])}\"\nlabels[-1] = f\"&gt;${int(bin_edges[-2])}\"\n\nX_test[\"income_group\"] = pd.qcut(X_test[\"person_income\"], q=6, labels=labels)\n\nacceptance_rates_income = X_test.groupby(\"income_group\").apply(lambda group: np.mean(preds[group.index] == 0))\n\nplt.figure(figsize=(10, 5))\nsns.barplot(x=acceptance_rates_income.index, y=acceptance_rates_income.values, palette=\"Blues_r\")\n\nplt.xlabel(\"Income Group\")\nplt.ylabel(\"Acceptance Rate\")\nplt.title(\"Acceptance Rates by Income Level\")\nplt.ylim(0.75, 1)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n\n\n\n\n\n\n\n\nFinally, we will look at acceptance rates by income level. As the chart above shows, this is a pretty linear relationship with higher income individuals being more likely to be accepted for a loan. This makes sense because higher income individuals are more likely to be able to pay back the loan."
  }
]