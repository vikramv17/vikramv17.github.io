<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vikram Vasan">
<meta name="dcterms.date" content="2025-05-19">
<meta name="description" content="Final Project Blog Post">

<title>Predicting Movie Success with Deep Learning and Embeddings – Vikram Vasan CSCI 0451 Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6de787833effe4777a6777a5e05fb578.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Vikram Vasan CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Predicting Movie Success with Deep Learning and Embeddings</h1>
                  <div>
        <div class="description">
          Final Project Blog Post
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Vikram Vasan </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 19, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="abstract" class="level1">
<h1>Abstract</h1>
<p>This paper presents a novel approach to predicting movie success, using only the list of people who worked on the film. While other approaches like that of <span class="citation" data-cites="SHARDA2006243">Sharda and Delen (<a href="#ref-SHARDA2006243" role="doc-biblioref">2006</a>)</span> have used metrics like production cost and MPAA ratings, we focus on the cast, crew, and production companies involved. This method is based on the idea that consumers are attracted to movie stars and directors when deciding which films to watch so it should be possible to use the people involved in a film to predict its success. We use a dataset of 45,466 movies from 1874 to 2017 from IMDB, which includes information about the cast, crew, and production companies as well as the average rating and number of votes for each film, its revenue, and its popularity. A deep learning approach is used to predict the rating, revenue, and popularity of a movie based on embeddings that represent the people involved in it and compare the success of using different subsets of the embeddings for each target variable. We find that the best results are obtained when using all of the embeddings together and we find the best success in predicting revenue and popularity while predicting the rating proved to be more difficult. The results suggest that the people involved in a film can be used to predict its success to a certain extent, but that other factors also play a significant role, explaining the better success seen by those like <span class="citation" data-cites="8281839">Quader et al. (<a href="#ref-8281839" role="doc-biblioref">2017</a>)</span>.</p>
<p><a href="https://github.com/vikramv17/cs451-project">Link to GitHub Repo</a></p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>What makes a good movie? What makes a successful movie? Are these questions synonymous or different entirely? The film industry is a multi-billion dollar business, and as such, predicting movie success is of great interest to studios and investors. Traditionally, it took industry expertise to have a sense of which movies would be successful, but with the advent of big data and machine learning, it is now possible to use data-driven approaches to make predictions. The industry is a complex ecosystem, and the success of a movie can be influenced by a multitude of factors. Some of these factors are easily quantifiable, such as production cost, MPAA ratings, and marketing strategies. Others are more subjective and harder to measure, such as the quality of the script or the chemistry between the cast members. Previous work has focused on the more quantifiable factors, however, these approaches often leave out what is potentially the most important factor: the people involved in the film. One would expect the cast, crew, and production companies all play a significant role in determining a movie’s success, and this paper aims to explore how we can use this information to make predictions.</p>
<p>Given the value in the film industry, it is not surprising that there has been a great deal of research into predicting movie success. <span class="citation" data-cites="SHARDA2006243">Sharda and Delen (<a href="#ref-SHARDA2006243" role="doc-biblioref">2006</a>)</span> used a variety of metrics to predict the success of movies, including production cost, MPAA ratings, and competition. They found that these factors could be used to make accurate predictions about a movie’s financial success. <span class="citation" data-cites="7a5eafb9-4f67-315d-a80f-c4df9cabba0d">Ravid (<a href="#ref-7a5eafb9-4f67-315d-a80f-c4df9cabba0d" role="doc-biblioref">1999</a>)</span> looked at the impact of star value in the cast and found conflicting results on their impact. <span class="citation" data-cites="8281839">Quader et al. (<a href="#ref-8281839" role="doc-biblioref">2017</a>)</span> used SVMs and Neural Networks to predict box-office success and found that budget was among the most important factors. That said they included factors like the number of screens which is not available until after the movie is released and is thus less useful for movie producers when deciding whether or not to make a movie. <span class="citation" data-cites="ZHANG20096580">Zhang, Luo, and Yang (<a href="#ref-ZHANG20096580" role="doc-biblioref">2009</a>)</span> did a similar thing with a multi-layer neural network to predict box office success using information only known before the theatrical release using factors like star power and marketing and found success.</p>
<p>The fundamental question that these attempts are missing is the question of quality not necessarily being related with revenue. Any movie enthusiast will tell you that there are many movies that are critically acclaimed but did not do well at the box office and vice versa. As such, simply predicting box office success, while important for production companies, is not the only metric of success. Another factor that these studies are missing is the fact that they are only incorporating small measures of the people involved in the film. While some of the aforementioned authors included a star power metric, this ignores the vast majority of the cast and the rest of the crew involved. Instead of distilling the people involved in a film down to a single number, we propose using embeddings to represent the people involved in a film. This allows us to capture the relationships between the people involved and how they may influence each other. These embeddings in conjunction with a multi-layer neural network, we predict will allow us to make predictions about a movie’s success, measured by rating, revenue, and popularity, not just box office returns. If this attempt proves successful, it could be integrated into the decision-making process along with other methods that use more traditional metrics for enhanced prediction success.</p>
<p>I will use a dataset of 45,466 movies from IMDB, a website that aggregates information about movies and allows for users to leave reviews and ratings. IMDB offers an average rating which will be one of the targets as well as a popularity metric which factors how often a movie is searched for and how many reviews it has received. We will also use the revenue of the film as a target variable to mirror the literature. The dataset includes information about the cast, crew, and production companies involved in each film with unique IDs for each person and company which will be used to create the embeddings. We will use various methods like class weighting, positional encodings, and attention pooling to improve the performance of our model.</p>
</section>
<section id="values-statement" class="level1">
<h1>Values Statement</h1>
<p>Potential users of this model include movie studios and investors looking to make decisions about which movies to produce. The goal of this project is to provide insights into the movie industry and how different characteristics influence a movie’s success, not to create a model that will be used to make decisions about which movies to produce. However, it is important to consider the ethical implications of using models like this in the decision-making process. If models like this can be proved successful, they could be used by movie studios to help make decisions. This could lead to a self-fulfilling situation where only certain types of movies are produced, which could limit the diversity of movies available to audiences. This could be problematic as it could lead to a homogenization of the movie industry and a lack of representation for certain groups. The choice to produce a movie is very important for the livelihoods of those involved in the production and the actors, and if this model is used to make those decisions, it could have a significant impact on their lives. Those trying to push the envelope of the movie industry may be discouraged from doing so if they know that their movie will not be produced because it does not fit the mold of what is expected to be successful. This could lead to a lack of innovation in the industry and a decrease in the quality of movies being produced. It is important to consider these ethical implications when using models like this to make decisions about which movies to produce. The goal of this project is better understand the movie industry, not to create a model that will be used to make decisions about which movies to produce.</p>
<p>Another potential user is moviegoers. If a model like this could be implemented in a personalized way, trained on a user’s preferences, it could be used to recommend movies to them. This could be a useful tool for moviegoers looking for new movies to watch, but it could also discourage them from watching movies that do not fit their typical preferences. Discouraging exploration and curiosity is not the goal of this project, and it is important to consider the implications of using models like this to make personal recommendations as well.</p>
<p>Overall my intent is to learn about the movie industry and how different characteristics influence a movie’s success. As a person who loves movies and machine learning, I want to combine these interests to learn about how well neural networks can be used to predict movie success. While a production version of such a model could be problematic and make the movie world less equitable, as discussed above, that is not the intention of this project. I do not wish for movie making decisions to be made by algorithms and I think that that potential future is a dire one.</p>
</section>
<section id="materials-and-methods" class="level1">
<h1>Materials and Methods</h1>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<p>The data comes from <a href="https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/data">Kaggle</a> and was collected using the <a href="https://www.themoviedb.org/?language=en-US">TMBD</a> API and <a href="https://grouplens.org/datasets/movielens/latest/">GroupLens</a>. There are several different sheets in the dataset but the main ones used are the Movies Metadata one, the Credits one, and the Ratings one. The metadata dataset includes basic information about 45,466 movies from 1874 to 2017 including the revenue, popularity, genre, and production companies. The credits dataset has the cast as well as the entire crew and departments that each individual worked in for each movie. Finally, the ratings dataset has 26,024,289 ratings from 270,896 users. The ratings are on a scale of 0 to 10 and are used to calculate the average rating for each movie. Unique movie IDs are used to join the relevant information from the different datasets together. Overall, the dataset is quite large and comprehensive in terms of movies and reviews. A potential source of bias is the fact that the dataset is from IMDB, which is a website that is primarily used by English-speaking audiences. This could lead to a situation where movies that are not in English or do not have a large following in English-speaking countries are underrepresented in the dataset especially when it comes to ratings. While this is a concern, it is important to note that the dataset does include movies from a variety of countries and languages. Additionally, the dataset is quite large and includes a wide range of movies from different genres and time periods, which should help to mitigate this bias.</p>
</section>
<section id="approach" class="level2">
<h2 class="anchored" data-anchor-id="approach">Approach</h2>
<p>The approach taken in this project is to use a deep learning model to predict the rating, revenue, and popularity of a movie based on the people involved in it as well as the production companies and genres. The target variables were <strong>rating</strong>, <strong>revenue</strong>, and <strong>popularity</strong>. The rating is the average rating of the movie on a scale of 0 to 10, the revenue is the total revenue of the movie in dollars, and the popularity is a score that is calculated based on the number of page visits and interactions for a given movie. The features used are the list of unique IDs that correspond to each member of the cast and crew as well as the production companies and genres. The unique IDs are used to create embeddings that represent the people involved in the film. The embeddings are then used as input to a multi-layer neural network to predict the target variables. The model is trained using a binary cross-entropy loss function with class weighting (to account for the unequal class distribution when predicting vote average), and the Adam optimizer is used for optimization. The model is evaluated using accuracy and a normalized mean absolute error as a proximity score given the multi-class context.</p>
<section id="data-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing">Data Preprocessing</h3>
<p>The collection of movies for each target variable is slightly different. For rating, we only include movies that have at least 100 ratings to filter out potential outliers. For revenue, we only include movies that have a revenue greater than 0 to filter out movies that did not make any money or have no revenue information. This leaves us with 7,428 movies for revenue, 45,535 for popularity, and 6031 for rating. The movies are then split into a training set (60%), a validation set (20%), and a test set (20%). The training set is used to train the model, the validation set is used to tune the hyperparameters, and the test set is used to evaluate the performance of the model. For the ratings we round down the ratings to the nearest integer to make it a multi-class classification problem. This leads to some class imbalance as ratings are approximately normally distributed with 6 being the most common rounded rating. To account for this we use class weighting to give more weight to the less common classes in the loss function. For revenue and popularity we simply use five equal sized quantiles to create the classes. This leads to a more balanced dataset for these two target variables so class weighting is not necessary.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="distribution.png" class="img-fluid figure-img"></p>
<figcaption>Distribution of Ratings</figcaption>
</figure>
</div>
</section>
<section id="embeddings" class="level3">
<h3 class="anchored" data-anchor-id="embeddings">Embeddings</h3>
<p>The embeddings are created using the unique IDs for each person and company involved in the film. There are three main embeddings used, the <em>cast embedding</em>, the <em>crew embedding</em>, and the <em>production company and genre embedding</em>. The cast embedding uses the IDs and is padded with zeros to ensure that all movies have the same length. The crew embedding is created in a similar way, but it also takes into account the department that each person worked in (directing, writing, etc.). This means that in one embedding, the different departments begin in fixed places in the embedding. These positions are determined according to the movie with the most crew members in that department and the rest of the movies are padded with zeros to ensure that the same departments are in the same place. This is important because it allows the model to understand the importance of each department in a movie by differentiating between the departments. It is important that order is preserved since those listed first in the credits usually played a bigger role. The production company and genre embedding is created in a similar way, but it uses the unique IDs for the production companies and genres instead of the people involved in the film. The embeddings are then concatenated together to create a single input vector for the model. Each embedding is also tested on its own to see which one is the most important for predicting each target variable.</p>
</section>
<section id="model" class="level3">
<h3 class="anchored" data-anchor-id="model">Model</h3>
<p>The model itself is a multi-layer neural network with several layers. The input layer takes in the concatenated embeddings with an embedding dimension of 25 along with a positional encoding layer to maintain a sense of the order of the people in the embeddings. The positional encodings simply capture where in the input each embedding is and this position is added to the embedding. The model then passes that through an attention pooling layer which uses softmax to weight the different embeddings based on their importance. This is important because not every unique ID is likely to be equally important. For example, the director or the lead actor is likely far more important than the fifth lighting designer. The attention pooling allows the model to learn these importances and incorporate them into the predictions. With a sense of the order of the embeddings and the importance of each embedding the model then passes the output through three layers of decreasing size followed by layer normalization, ReLU activation, and a 30% dropout to avoid overfitting.</p>
</section>
<section id="gender-bias-audit" class="level3">
<h3 class="anchored" data-anchor-id="gender-bias-audit">Gender Bias Audit</h3>
<p>The data comes with the genders of each person involved in the film. This is important to consider as it could lead to a situation where the model is biased towards a certain gender. To audit this, after the model is tested on the test set we extract the genders of each person involved in the film and calculate the average gender for each movie (women are mapped to 0 and men are mapped to 1). We then calculate the difference between the average gender of the predictions for each category and the true labels. This allows us to see if the model is biased towards a certain gender, giving, for example, a higher rating to movies with more men. We perform this audit for the <em>revenue</em> target variable as it is the most important one for the movie industry and the one that our model performed the best on.</p>
</section>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>The results of the model are shown in the table below. The IDs column indicates which of the embeddings were used where <em>combined</em> means that all of the embeddings were used together. The baseline measures indicate the results for a theoretical model that simply predicts the mean of the target variable for each class. The bolded test metrics indicate that the model performed better than the baseline with the italicized metrics indicating the embeddings that performed the best for each target variable. The accuracy is the standard accuracy metric, while the proximity score is a normalized mean absolute error that takes into account the multi-class nature of the problem giving a sense for how close the predictions were to the actual values (predicting 3 for a class of 4 is better than predicting 1 for a class of 4).</p>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 15%">
<col style="width: 13%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>IDs</th>
<th>Target</th>
<th>Movies</th>
<th>Base Acc</th>
<th>Test Acc</th>
<th>Base Prox</th>
<th>Test Prox</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>cast</td>
<td>revenue</td>
<td>7428</td>
<td>0.200</td>
<td><strong>0.297</strong></td>
<td>0.702</td>
<td><strong>0.710</strong></td>
</tr>
<tr class="even">
<td>crew</td>
<td>revenue</td>
<td>7428</td>
<td>0.200</td>
<td><strong>0.355</strong></td>
<td>0.702</td>
<td><strong>0.758</strong></td>
</tr>
<tr class="odd">
<td>genre + prod</td>
<td>revenue</td>
<td>7428</td>
<td>0.200</td>
<td><strong>0.351</strong></td>
<td>0.702</td>
<td><strong>0.751</strong></td>
</tr>
<tr class="even">
<td>combined</td>
<td>revenue</td>
<td>7428</td>
<td>0.200</td>
<td><strong><em>0.396</em></strong></td>
<td>0.702</td>
<td><strong><em>0.779</em></strong></td>
</tr>
<tr class="odd">
<td>cast</td>
<td>popularity</td>
<td>45535</td>
<td>0.200</td>
<td><strong>0.339</strong></td>
<td>0.702</td>
<td><strong>0.754</strong></td>
</tr>
<tr class="even">
<td>crew</td>
<td>popularity</td>
<td>45535</td>
<td>0.200</td>
<td><strong><em>0.348</em></strong></td>
<td>0.702</td>
<td><strong>0.762</strong></td>
</tr>
<tr class="odd">
<td>genre + prod</td>
<td>popularity</td>
<td>45535</td>
<td>0.200</td>
<td><strong>0.335</strong></td>
<td>0.702</td>
<td><strong>0.757</strong></td>
</tr>
<tr class="even">
<td>combined</td>
<td>popularity</td>
<td>45535</td>
<td>0.200</td>
<td><strong>0.339</strong></td>
<td>0.702</td>
<td><strong><em>0.795</em></strong></td>
</tr>
<tr class="odd">
<td>cast</td>
<td>vote average</td>
<td>6031</td>
<td>0.420</td>
<td>0.359</td>
<td>0.866</td>
<td>0.807</td>
</tr>
<tr class="even">
<td>crew</td>
<td>vote average</td>
<td>6031</td>
<td>0.420</td>
<td>0.318</td>
<td>0.866</td>
<td>0.801</td>
</tr>
<tr class="odd">
<td>genre + prod</td>
<td>vote average</td>
<td>6031</td>
<td>0.420</td>
<td>0.260</td>
<td>0.866</td>
<td>0.771</td>
</tr>
<tr class="even">
<td>combined</td>
<td>vote average</td>
<td>6031</td>
<td>0.420</td>
<td><em>0.376</em></td>
<td>0.866</td>
<td><em>0.820</em></td>
</tr>
</tbody>
</table>
<p>Overall, the model was able to outperform the baseline when predicting revenue and popularity, but not when predicting the vote average. Several attempts were made to improve the model including changing the structure of the layers, using self attention, and using different optimizers however these were the best results we were able to achieve. That said, while disappointing that the model was unable to predict the vote average, it is still promising to see that the model was able to outperform the baseline for revenue and popularity. This suggests that the people involved in a film can be used to predict its success to a certain extent, but that other factors also play a significant role as past researchers have achieved much higher accuracies. The model was able to learn the relationships between the people involved in a film and how they may influence each other, which is an important step in understanding the movie industry. The attention pooling layer was particularly useful in this regard as it allowed the model to learn the importance of each embedding and incorporate that into the predictions. While not included in the table, the results before adding attention pooling and positional encodings were significantly worse.</p>
<p>Below is a chart of the percent difference between the proximity score and the baseline for each target and embedding combination. We observe that in all cases, combining all of the embeddings together leads to the best results. This is not surprising as it gives the model more information to work with. Other relationships are less clear so it is hard to determine which of the three embeddings on their own is the most important. Perhaps surprisingly, the cast embedding performed the worst for revenue and popularity but this is unlikely to be significant.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="proximity_scores.png" class="img-fluid figure-img"></p>
<figcaption>Proximity Scores</figcaption>
</figure>
</div>
<p>Finally, the results of the gender bias audit are shown in the figure below. The plot on the left shows the average gender of the people for the movies in each class where 4 corresponds to the highest revenue and 0 corresponds to the lowest revenue. Here we see that on average, the average gender increases with the revenue class, meaning that more successful movies tend to have more men (as a percentage of the cast and crew) than less successful ones. This already shows that the industry itself is biased towards men with over 71% of people working on movies being men on average. Our model is likely to learn from this bias and replicate it in its predictions.</p>
<p>The plot on the right shows the difference between the average gender of the predictions and the true labels for each class. Here we see that the model seems to be even more biased towards men than the data itself with average gender increasing even more with the revenue class in the predictions than in the data. This suggests that the model exacerbates the bias in the data however it is important to note that the differences observed are very small and may not be significant. That said, this is an important consideration when using models like this to make decisions about which movies to produce. It is important to ensure that the model is not biased towards a certain group and that it is not replicating or intensify existing biases in the data. In the future, it would be interesting to test the bias of the model on the other target variables as well to see if similar biases are observed with other factors like race or age (unfortunately this information wasn’t included in the dataset).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="gender.png" class="img-fluid figure-img"></p>
<figcaption>Gender Bias Audit</figcaption>
</figure>
</div>
</section>
<section id="concluding-discussion" class="level1">
<h1>Concluding Discussion</h1>
<p>The main takeaway from these results is that the people involved in a film can be helpful in predicting its success. That said, solely looking at this information is not enough to make accurate predictions and other factors like script quality, marketing, and competition also likely play a significant role. It would be interesting to see how a model like those used in the literature could be combined with this model to improve the predictions. The results of our contemporaries suggest that the people involved in a film are not the only factor that determines its success, but we have now proven that they are not an insignificant factor either. Future work that combines the two approaches could lead to even better predictions and a better understanding of the movie industry.</p>
<p>The project worked in the sense that we were able to use the people involved in a film to predict its success by employing embeddings and a multi-layer neural network. Since the main goal was to see if this approach was even possible, we are happy with the results. With more time and resources, further fine tuning and optimization of the model could likely lead to even better results but we are satisfied with my proof of this concept’s viability. After the initial testing workflow was developed, a lot of the time and effort was spent tweaking and testing the model to see if we could get better results. The use of class weighting, positional encodings, and attention pooling were all successful in improving the model’s performance and more techniques were attempted. There are undoubtedly more things that could be tried to improve the model but we are happy with our results given the extent of the experiments we conducted.</p>
</section>
<section id="group-contributions-statement" class="level1">
<h1>Group Contributions Statement</h1>
<p>As I was the only person working on this project, I was responsible for all aspects of the project and I wrote all of the code and the report. I started by cleaning the data and testing some of the quantitative features on simple <em>out-of-the-box</em> models to get a sense for the predictive power of the data in the movies context. After reading some of the literature, I decided to pivot to using embeddings and focusing on the people involved in the film as this was, as far as I could tell, a novel approach. I then spent a lot of time trying to figure out how to create the embeddings and how to structure the model. After that, I spent a lot of time testing different structures and hyperparameters to see what worked best. I also spent time writing the report and creating the figures. Overall, I am happy with the results and I think that this project was a success.</p>
</section>
<section id="personal-reflection" class="level1">
<h1>Personal Reflection</h1>
<p>Over the course of this project I learned a lot about neural networks and machine learning in general which was my main goal. I wanted to get hands on experience tinkering with neural networks in order to gain a better understanding of how they work and how to use them. Before I had simply been using them as a black box and I wanted to learn more about how they actually work so I can more effectively use them in the future. I also learned a lot about how to work with embeddings. Previously I thought of embeddings only in the context of NLP and text data which is why I was excited to try using them in a different context. I learned a lot about how to create and use embeddings and what techniques can be used to improve their performance like positional encodings and attention pooling. I also learned a lot about the movie industry and how different characteristics influence a movie’s success. I have always been interested in movies and this project allowed me to combine my interests in movies and machine learning which was a great experience. Overall, I am happy with the results and I think that this project was a success.</p>
<p>I did not necessarily set out on this project with a specific goal in mind, but after exploring the data, the literature, and different models I was able to find a direction that I was interested in. Once I knew that I wanted to use embeddings that represent the people involved in a movie, my goal became one of proving a concept. I wanted to see if this approach was even possible and if it could lead to better predictions than the baseline. I wasn’t trying to beat the best models in the literature, but rather to see if this novel approach could be successful in order to understand if it could be combined with other approaches in the future. In that sense, I think this project was a success for the most part. I would have liked to see better results for the vote average but I think that this is a promising start and that it could be improved to the point where predicting vote average is also possible.</p>
<p>I will carry my improved understanding of neural networks and embeddings into the future and I think that this project has given me a solid foundation to build on. While I don’t know if I will have the opportunity to work with neural networks again, at the very least I now have a better understanding of how they work which will help as I read about the advancements in the field of machine learning. It is such a fast moving field and I think that this baseline and the hands-on experience I have gained will help me to keep up with the advancements in the field.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-8281839" class="csl-entry" role="listitem">
Quader, Nahid, Md. Osman Gani, Dipankar Chaki, and Md. Haider Ali. 2017. <span>“A Machine Learning Approach to Predict Movie Box-Office Success,”</span> 1–7. <a href="https://doi.org/10.1109/ICCITECHN.2017.8281839">https://doi.org/10.1109/ICCITECHN.2017.8281839</a>.
</div>
<div id="ref-7a5eafb9-4f67-315d-a80f-c4df9cabba0d" class="csl-entry" role="listitem">
Ravid, S. Abraham. 1999. <span>“Information, Blockbusters, and Stars: A Study of the Film Industry.”</span> <em>The Journal of Business</em> 72 (4): 463–92. <a href="http://www.jstor.org/stable/10.1086/209624">http://www.jstor.org/stable/10.1086/209624</a>.
</div>
<div id="ref-SHARDA2006243" class="csl-entry" role="listitem">
Sharda, Ramesh, and Dursun Delen. 2006. <span>“Predicting Box-Office Success of Motion Pictures with Neural Networks.”</span> <em>Expert Systems with Applications</em> 30 (2): 243–54. https://doi.org/<a href="https://doi.org/10.1016/j.eswa.2005.07.018">https://doi.org/10.1016/j.eswa.2005.07.018</a>.
</div>
<div id="ref-ZHANG20096580" class="csl-entry" role="listitem">
Zhang, Li, Jianhua Luo, and Suying Yang. 2009. <span>“Forecasting Box Office Revenue of Movies with BP Neural Network.”</span> <em>Expert Systems with Applications</em> 36 (3, Part 2): 6580–87. https://doi.org/<a href="https://doi.org/10.1016/j.eswa.2008.07.064">https://doi.org/10.1016/j.eswa.2008.07.064</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>